---
title: "HW6"
author: "Xinyu Shen xs2384"
date: "2019/11/22"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(modelr)
library(purrr)
```


## Problem 1


#### Import and clean the data


```{r, warning=FALSE}

df = read_csv("./data/birthweight.csv") %>% janitor::clean_names() %>% mutate(
  babysex = as.factor(babysex),
  frace = as.factor(frace),
  malform = as.factor(malform),
  mrace = as.factor(mrace)
)

# check missing value
nrow(df[is.na(df),])

```

From above, we can see that there is no missing value in the dataset. 



#### Model Selection


I use the stepwise to select model

```{r}

my_model = step(lm(bwt~., data = df), direction = "backward")


```


The model selected by stepwise is:

```{r}
my_model$call
```


#### Plot of residuals vs fitted value

```{r}
df %>% add_predictions(my_model) %>% add_residuals(my_model) %>% ggplot(aes(x = pred, y = resid)) + geom_point() + geom_smooth(se = F) + theme_bw() + labs(x = "Fitted Value", y = 'Residuals', title = "Residuals vs Fitted value") + theme(plot.title = element_text(hjust = 0.5))
```

From the plot above, we can see that the residuals are normally distributed when fitted value is from 2000 to 4000. 


#### Comparing with two models

```{r}
cv_df = crossv_mc(df, 100)

cv_df = cv_df %>% 
  mutate(train = map(train, as_tibble),
    test = map(test, as_tibble)) 

cv_df = cv_df %>% mutate(
    my_model = map(train, ~lm(formula = bwt ~ babysex + bhead + blength + delwt + fincome + 
    gaweeks + mheight + mrace + parity + ppwt + smoken, data =.x)),
    model_1 = map(train, ~lm(bwt ~ blength + gaweeks, data =.x)),
    model_2 = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex + bhead * blength * babysex, data = .x))

  ) %>% 
  mutate(
      rmse_my_model = map2_dbl(my_model, test, ~rmse(model = .x, data = .y)),
      rmse_model_1 = map2_dbl(model_1, test, ~rmse(model = .x, data = .y)),
      rmse_model_2 = map2_dbl(model_2, test, ~rmse(model = .x, data = .y))) 

cv_df %>% select(starts_with("rmse")) %>% 
  pivot_longer(everything() ,
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse, fill = model)) + geom_violin(alpha = 0.5) + theme_bw()
```


From the violin plot above, we can see that my choice of model has the lowest rmse compared with other two models, which means my model has least predicted error. 



## Problem 2

